---
title: "Assigning with DADA2"
author: "Liangzi"
date: "2025-03-05"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                       fig.align = "center",
                      # Send figures generated in this file to this folder below
                      fig.path = "../figures/02_AssignASVs/")
```

# Goals

1. Infer Errors in our sequences, separately on forward and reverse reads.
2. Assign ASVs on both forward and reverse reads separately. Apply the error model.
3. Merge forward and reverse ASVs into "contiguous ASVs".
4. Generate first draft of ASV count table.
5. Quality Trimming ASV length.
6. Remove chimeras.
7. Assign Taxonomy with Silva Database.
8. Write out relevant files: 'asv_table', 'asv_fastas', 'tax_table', and 'sample_data'.

## Input
1. Filtered fastq.gz files generated from '01_QualityTrimming.Rmd'.
2. Sample name vector.

## Output
1. 'asv_table'
2. 'asv_fastas'
3. 'tax_table'
4. 'sample_data'

# Set up the encironment

## Set Seed
```{r set-seed}
set.seed(238428)
```

## Load Packages
```{r load-packages}
pacman::p_load(tidyverse, devtools, dada2, 
               patchwork, DT, install = FALSE)
```

# Load Filtered Fastq Files
```{r load-filtered-fastqs}
# Place filtered seq into a variable
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# Intuition Check 
filtered_fastqs_path

# create Forward vector
filtered_forward_reads <- 
  list.files(filtered_fastqs_path, pattern = "R1_filtered.fastq.gz",
             full.names = TRUE)
# Check 
filtered_forward_reads[1:5]

# Reverse vector
filtered_reverse_reads <- 
    list.files(filtered_fastqs_path, pattern = "R2_filtered.fastq.gz",
             full.names = TRUE)  
# Check 
filtered_reverse_reads[1:5]
```

# Sample Name
```{r sample-name}
# Create vector of sample names from the filenames 
sample_names <- sapply(strsplit(basename(filtered_forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)
```

# Error Modelling
```{r learn-errors}
# Forward Reads
error_forward_reads <-
  learnErrors(filtered_forward_reads, multithread = 6)
# Forward Error Plot
forward_error_plot <- 
  plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Reads: Error Model")

# Reverse Reads
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads, multithread = 6)

# Reverse Error Plot
reverse_error_plot <- 
  plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Reads: Error Model")

# Put the two plots together
forward_error_plot + reverse_error_plot
```

# Infer ASVs
```{r infer-ASVs}
# Forward ASVs
dada_forward <- 
  dada(filtered_forward_reads,
       err = error_forward_reads, 
       multithread = 6) # Why do we choose 6 rather than 'TRUE'???

# Take a look at the data
typeof(dada_forward)
dada_forward

# Reverse ASVs
dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads,
                     multithread = 6)
# Check data
dada_reverse[30]
```

# Merge Forward and Reverse ASVs
```{r merge ASVs}
merged_ASVs <-
  mergePairs(dada_forward, filtered_forward_reads, 
             dada_reverse, filtered_reverse_reads,
             verbose = TRUE)

# Evaluate the data output
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)

# Inspect further: Inspect the whole merger data.frame
head(merged_ASVs)
# Inspect the merger data.frame from the 20210602-MA-ABB1P
merged_ASVs$`20210602-MA-ABB1P_R1_filtered.fastq.gz`
#Or: head(merged_ASVs[[3]]) 
# Check the output from head(merged_ASVs), you can see where did the `20210602-MA-ABB1P_R1_filtered.fastq.gz` locate
```

# Create Raw ASV Count Table
```{r raw-ASV-count-table}
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Check the type and dimensions of the data
dim(raw_ASV_table)
typeof(raw_ASV_table)
class(raw_ASV_table)

# Write out the file 'raw_ASV_table' to data/01_DADA2/
write.table(raw_ASV_table, file = "data/01_DADA2/raw_ASV_counts.tsv", 
            sep = "\t", quote = FALSE, col.names = NA)
```

# Assess the ASV Length
```{r assess-ASV-length}

# Creating a table to inspect the distribution of ASV length
table(nchar(getSequences(raw_ASV_table)))

# Plot
data.frame(ASV_Length = nchar(getSequences(raw_ASV_table))) %>%
  ggplot(aes(x = ASV_Length)) +
  geom_histogram() +
  # modify x-axis limits
  scale_x_continuous(limits = c(0, 500)) + 
  labs(title = "Raw ASV Lengths",
       y = "Number of ASVs", x = "ASV Sequence Length (bps)")
```

# Trim ASVs
```{r trim-ASVs}
raw_ASV_table_trimmed <-
  raw_ASV_table[,nchar(getSequences(raw_ASV_table)) == 245] # [raws, columns], checkout the output_take 245 which is the largest (shows that 245-3160)

# Intuition check
table(nchar(getSequences(raw_ASV_table_trimmed)))
```

# Remove Chimeras
```{r remove-chimeras}
noChimeras_ASV_table <- 
  removeBimeraDenovo(raw_ASV_table_trimmed,
                     method="consensus",
                     multithread = 6, 
                     verbose=TRUE)
# Structure of data?
dim(noChimeras_ASV_table)
dim(raw_ASV_table_trimmed)

```

# Track the number of reads DADA2 workflow

# Assign Taxonomy


